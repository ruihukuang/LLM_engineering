# Week 3  

## day 2  

Context  

Use T4 GPU in the Google Colab to run pipelines to do the following tasks.  
sentiment-analysis   
named entity recognition  
question answering with provided contexts  
text summarization  
translation from English to France  
translation from English to Spanish  
classifying a sentence based on provided categories  
generation of remaining words based on provided words in a sentence  
creation of an image based on provided descriptions  
generating an audio file based on provided words    


Screenshots show outputs for these tasks.  



## day 3  

Context  

Use the following models to tokenize input messages.  

meta-llama/Meta-Llama-3.1-8B 
meta-llama/Meta-Llama-3.1-8B-Instruct  
microsoft/Phi-3-mini-4k-instruct  
Qwen/Qwen2-7B-Instruct  
bigcode/starcoder2-3b  


## day 4  

Context 

Use the following models to tokenize input messages and then to use system/user messages to ask these models to tell a light-heared joke for data scientists.  

meta-llama/Meta-Llama-3.1-8B-Instruct  
microsoft/Phi-3-mini-4k-instruct 

Screenshots below show outputs.  


