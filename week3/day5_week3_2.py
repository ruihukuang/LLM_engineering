# -*- coding: utf-8 -*-
"""Day5_week3_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d3ClkmVbUL4y3_vyKYuOPzpVezspORA_
"""

from transformers import AutoModelForSpeechSeq2Seq
from transformers import AutoProcessor
import torch
from transformers import pipeline

AUDIO_MODEL = "openai/whisper-medium"
speech_model = AutoModelForSpeechSeq2Seq.from_pretrained(AUDIO_MODEL, torch_dtype=torch.float16, low_cpu_mem_usage=True, use_safetensors=True)
speech_model.to('cuda')
processor = AutoProcessor.from_pretrained(AUDIO_MODEL)

pipe = pipeline(
    "automatic-speech-recognition",
    model=speech_model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    torch_dtype=torch.float16,
    device='cuda',
)

from google.colab import drive

# New capability - connect this Colab to my Google Drive
# See immediately below this for instructions to obtain denver_extract.mp3

drive.mount("/content/drive")
audio_filename = "/content/drive/My Drive/denver_extract.mp3"

# Use the Whisper OpenAI model to convert the Audio to Text
result = pipe(audio_filename,return_timestamps=True)

transcription = result["text"]
print(transcription)

from IPython.display import Markdown, display, update_display

display(Markdown(transcription))